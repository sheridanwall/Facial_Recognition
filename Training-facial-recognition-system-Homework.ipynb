{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Training a facial recognition system (Homework, Part 1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGXRAQI_u7kp"
      },
      "source": [
        "# A custom facial recognition system\n",
        "\n",
        "Once upon a time the NYT [built a system to recognize members of Congress](https://open.nytimes.com/how-the-new-york-times-uses-software-to-recognize-members-of-congress-29b46dd426c7). If they can do it, why not us?\n",
        "\n",
        "## Obtaining the data\n",
        "\n",
        "To train a model to recognize members of Congress, we need *labeled pictures of members of Congress.* Luckily I spent a million years doing that for you!\n",
        "\n",
        "Since I haven't memorized everyone in Congress, I started with a [a list of members of legislators downloaded from GitHub](https://github.com/unitedstates/congress-legislators)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqernfINvjyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "1657cd35-0199-455d-f4b9-776f2403238b"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://theunitedstates.io/congress-legislators/legislators-current.csv\")\n",
        "df.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>last_name</th>\n",
              "      <th>first_name</th>\n",
              "      <th>middle_name</th>\n",
              "      <th>suffix</th>\n",
              "      <th>nickname</th>\n",
              "      <th>full_name</th>\n",
              "      <th>birthday</th>\n",
              "      <th>gender</th>\n",
              "      <th>type</th>\n",
              "      <th>state</th>\n",
              "      <th>district</th>\n",
              "      <th>senate_class</th>\n",
              "      <th>party</th>\n",
              "      <th>url</th>\n",
              "      <th>address</th>\n",
              "      <th>phone</th>\n",
              "      <th>contact_form</th>\n",
              "      <th>rss_url</th>\n",
              "      <th>twitter</th>\n",
              "      <th>facebook</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youtube_id</th>\n",
              "      <th>bioguide_id</th>\n",
              "      <th>thomas_id</th>\n",
              "      <th>opensecrets_id</th>\n",
              "      <th>lis_id</th>\n",
              "      <th>fec_ids</th>\n",
              "      <th>cspan_id</th>\n",
              "      <th>govtrack_id</th>\n",
              "      <th>votesmart_id</th>\n",
              "      <th>ballotpedia_id</th>\n",
              "      <th>washington_post_id</th>\n",
              "      <th>icpsr_id</th>\n",
              "      <th>wikipedia_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brown</td>\n",
              "      <td>Sherrod</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sherrod Brown</td>\n",
              "      <td>1952-11-09</td>\n",
              "      <td>M</td>\n",
              "      <td>sen</td>\n",
              "      <td>OH</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>https://www.brown.senate.gov</td>\n",
              "      <td>503 Hart Senate Office Building Washington DC ...</td>\n",
              "      <td>202-224-2315</td>\n",
              "      <td>http://www.brown.senate.gov/contact/</td>\n",
              "      <td>http://www.brown.senate.gov/rss/feeds/?type=al...</td>\n",
              "      <td>SenSherrodBrown</td>\n",
              "      <td>SenatorSherrodBrown</td>\n",
              "      <td>SherrodBrownOhio</td>\n",
              "      <td>UCgy8jfERh-t_ixkKKoCmglQ</td>\n",
              "      <td>B000944</td>\n",
              "      <td>136.0</td>\n",
              "      <td>N00003535</td>\n",
              "      <td>S307</td>\n",
              "      <td>H2OH13033,S6OH00163</td>\n",
              "      <td>5051.0</td>\n",
              "      <td>400050</td>\n",
              "      <td>27018.0</td>\n",
              "      <td>Sherrod Brown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29389.0</td>\n",
              "      <td>Sherrod Brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cantwell</td>\n",
              "      <td>Maria</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Maria Cantwell</td>\n",
              "      <td>1958-10-13</td>\n",
              "      <td>F</td>\n",
              "      <td>sen</td>\n",
              "      <td>WA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>https://www.cantwell.senate.gov</td>\n",
              "      <td>511 Hart Senate Office Building Washington DC ...</td>\n",
              "      <td>202-224-3441</td>\n",
              "      <td>http://www.cantwell.senate.gov/public/index.cf...</td>\n",
              "      <td>http://www.cantwell.senate.gov/public/index.cf...</td>\n",
              "      <td>SenatorCantwell</td>\n",
              "      <td>senatorcantwell</td>\n",
              "      <td>SenatorCantwell</td>\n",
              "      <td>UCN52UDqKgvHRk39ncySrIMw</td>\n",
              "      <td>C000127</td>\n",
              "      <td>172.0</td>\n",
              "      <td>N00007836</td>\n",
              "      <td>S275</td>\n",
              "      <td>S8WA00194,H2WA01054</td>\n",
              "      <td>26137.0</td>\n",
              "      <td>300018</td>\n",
              "      <td>27122.0</td>\n",
              "      <td>Maria Cantwell</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39310.0</td>\n",
              "      <td>Maria Cantwell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cardin</td>\n",
              "      <td>Benjamin</td>\n",
              "      <td>L.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Benjamin L. Cardin</td>\n",
              "      <td>1943-10-05</td>\n",
              "      <td>M</td>\n",
              "      <td>sen</td>\n",
              "      <td>MD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>https://www.cardin.senate.gov</td>\n",
              "      <td>509 Hart Senate Office Building Washington DC ...</td>\n",
              "      <td>202-224-4524</td>\n",
              "      <td>http://www.cardin.senate.gov/contact/</td>\n",
              "      <td>http://www.cardin.senate.gov/rss/feeds/?type=all</td>\n",
              "      <td>SenatorCardin</td>\n",
              "      <td>senatorbencardin</td>\n",
              "      <td>senatorcardin</td>\n",
              "      <td>UCiQaJnMzlfzzG3VESgyZChA</td>\n",
              "      <td>C000141</td>\n",
              "      <td>174.0</td>\n",
              "      <td>N00001955</td>\n",
              "      <td>S308</td>\n",
              "      <td>H6MD03177,S6MD03177</td>\n",
              "      <td>4004.0</td>\n",
              "      <td>400064</td>\n",
              "      <td>26888.0</td>\n",
              "      <td>Ben Cardin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15408.0</td>\n",
              "      <td>Ben Cardin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carper</td>\n",
              "      <td>Thomas</td>\n",
              "      <td>Richard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Thomas R. Carper</td>\n",
              "      <td>1947-01-23</td>\n",
              "      <td>M</td>\n",
              "      <td>sen</td>\n",
              "      <td>DE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>https://www.carper.senate.gov/public</td>\n",
              "      <td>513 Hart Senate Office Building Washington DC ...</td>\n",
              "      <td>202-224-2441</td>\n",
              "      <td>http://www.carper.senate.gov/public/index.cfm/...</td>\n",
              "      <td>http://www.carper.senate.gov/public/index.cfm/...</td>\n",
              "      <td>SenatorCarper</td>\n",
              "      <td>tomcarper</td>\n",
              "      <td>senatorcarper</td>\n",
              "      <td>UCgLnvbKwu4B3navofj6Qvvw</td>\n",
              "      <td>C000174</td>\n",
              "      <td>179.0</td>\n",
              "      <td>N00012508</td>\n",
              "      <td>S277</td>\n",
              "      <td>S8DE00079</td>\n",
              "      <td>663.0</td>\n",
              "      <td>300019</td>\n",
              "      <td>22421.0</td>\n",
              "      <td>Tom Carper</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15015.0</td>\n",
              "      <td>Tom Carper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Casey</td>\n",
              "      <td>Robert</td>\n",
              "      <td>P.</td>\n",
              "      <td>Jr.</td>\n",
              "      <td>Bob</td>\n",
              "      <td>Robert P. Casey, Jr.</td>\n",
              "      <td>1960-04-13</td>\n",
              "      <td>M</td>\n",
              "      <td>sen</td>\n",
              "      <td>PA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>https://www.casey.senate.gov</td>\n",
              "      <td>393 Russell Senate Office Building Washington ...</td>\n",
              "      <td>202-224-6324</td>\n",
              "      <td>https://www.casey.senate.gov/contact/</td>\n",
              "      <td>http://www.casey.senate.gov/rss/feeds/?all</td>\n",
              "      <td>SenBobCasey</td>\n",
              "      <td>SenatorBobCasey</td>\n",
              "      <td>SenatorBobCasey</td>\n",
              "      <td>UCtVssXhx-KuZa-hSvnsnJ0A</td>\n",
              "      <td>C001070</td>\n",
              "      <td>1828.0</td>\n",
              "      <td>N00027503</td>\n",
              "      <td>S309</td>\n",
              "      <td>S6PA00217</td>\n",
              "      <td>47036.0</td>\n",
              "      <td>412246</td>\n",
              "      <td>2541.0</td>\n",
              "      <td>Bob Casey, Jr.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40703.0</td>\n",
              "      <td>Bob Casey Jr.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  last_name first_name  ... icpsr_id    wikipedia_id\n",
              "0     Brown    Sherrod  ...  29389.0   Sherrod Brown\n",
              "1  Cantwell      Maria  ...  39310.0  Maria Cantwell\n",
              "2    Cardin   Benjamin  ...  15408.0      Ben Cardin\n",
              "3    Carper     Thomas  ...  15015.0      Tom Carper\n",
              "4     Casey     Robert  ...  40703.0   Bob Casey Jr.\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxIkkIuiwByF"
      },
      "source": [
        "For each row, I combined their first and last name and used [Google Images Downloader](https://github.com/hardikvasa/google-images-download) to search Google Image Search for their name and download 30 images. Each image is stored in a folder named after the Congressperson.\n",
        "\n",
        "```\n",
        "downloads/\n",
        "├─ congressperson_xyz/\n",
        "│  ├─ 1.jpg\n",
        "│  ├─ 2.jpg\n",
        "│  ├─ 3.jpg\n",
        "├─ congressperson_abc/\n",
        "   ├─ 1.jpg\n",
        "   ├─ 2.jpg\n",
        "   ├─ 3.jpg\n",
        "...\n",
        "```\n",
        "That ended up with about 8GB of images, which I then resized using [ImageMagick](https://imagemagick.org/) to a max size of 1080x1080. I guess some of the pictures were very high-res, that got us down to around 2GB.\n",
        "\n",
        "### Just the faces, please\n",
        "\n",
        "Since human beings change their clothes each day, the *face* is the thing that allows us to tell different people apart. So I then ran each image through [MTCNN](https://github.com/ipazc/mtcnn) to cut out the faces and save them separately. So if we had an image with four faces in it, now we have four separate images instead.\n",
        "\n",
        "For a single member of Congress, all of the faces we found in all of the images of them are stored in a folder named after them.\n",
        "\n",
        "```\n",
        "faces/\n",
        "├─ congressperson_xyz/\n",
        "│  ├─ 1_face0.jpg\n",
        "│  ├─ 1_face1.jpg\n",
        "│  ├─ 2_face0.jpg\n",
        "│  ├─ 3_face0.jpg\n",
        "│  ├─ 3_face1.jpg\n",
        "│  ├─ 3_face2.jpg\n",
        "├─ congressperson_abc/\n",
        "   ├─ 1_face0.jpg\n",
        "   ├─ 2_face0.jpg\n",
        "   ├─ 2_face1.jpg\n",
        "   ├─ 3_face0.jpg\n",
        "...\n",
        "```\n",
        "\n",
        "## Pull in the data\n",
        "\n",
        "Start by downloading [faces.zip](https://drive.google.com/file/d/1-26HtaU6_PfJm-FizHSgJpUh_KRPO60S/view?usp=sharing), then uploading it to your Google Drive.\n",
        "\n",
        "Then, to import the data into this notebook, we'll need to connect Google Colab to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04iWfY6LKwc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096d9356-c0e2-4e25-e48f-d5dddbf483f0"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Pe1tGDzgdr"
      },
      "source": [
        "This code connects our Google Drive to the `gdrive` folder. The actual contents of your Google Drive will be in `grdrive/MyDrive`.\n",
        "\n",
        "Now we can copy `faces.zip` over and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF8WuavnK2A4",
        "outputId": "570997c7-ceab-497c-cd6d-ec0a34b5cd8b"
      },
      "source": [
        "# Copy faces.zip into the current folder\n",
        "!cp /content/gdrive/MyDrive/faces.zip .\n",
        "\n",
        "# Unzip it\n",
        "!unzip faces.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/gdrive/MyDrive/faces.zip': No such file or directory\n",
            "unzip:  cannot find or open faces.zip, faces.zip.zip or faces.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFpOy-LZH2f3"
      },
      "source": [
        "After you run the code below, click the little folder icon on the left-hand side of the screen. You can browse around and see what files came out of it! You probably need to click the little folder refresh icon, too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEpJiehFKJyC"
      },
      "source": [
        "## Looking at the images\n",
        "\n",
        "If you want to look at the images, you can use this code. It picks 16 random ones and displays them in a grid. **If you're feeling lazy, just continue onward without doing it!!!**\n",
        "\n",
        "```python\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a list of all files\n",
        "filenames = glob.glob(\"faces/**/*\")\n",
        "\n",
        "# Let's look at them!!!\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, filename in enumerate(random.sample(filenames, 16)):\n",
        "  ax = plt.subplot(4, 4, i + 1)\n",
        "  img = plt.imread(filename)\n",
        "  plt.imshow(img)\n",
        "  plt.title(filename.split(\"/\")[1])\n",
        "  plt.axis(\"off\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "gm8GDfHlKCcj",
        "outputId": "8406e6a5-b49d-47e8-d7bb-e04190f32ea9"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "# Get a list of all files\n",
        "filenames = glob.glob(\"faces/**/*\")\n",
        " \n",
        "# Let's look at them!!!\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, filename in enumerate(random.sample(filenames, 16)):\n",
        "  ax = plt.subplot(4, 4, i + 1)\n",
        "  img = plt.imread(filename)\n",
        "  plt.imshow(img)\n",
        "  plt.title(filename.split(\"/\")[1])\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c55129ae6bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Let's look at them!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoDyCuv-z38Z"
      },
      "source": [
        "# Now, machine learning!\n",
        "\n",
        "## Tensorflow setup\n",
        "\n",
        "Let's start by importing Tensorflow and whatever else we might need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG303BreMjUO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clBwauP20AJO"
      },
      "source": [
        "So far our images have always been RGB and sized 224x224, so that's what we're going to stick with again. We use 224x224 because the networks we've seen are trained with that size, so it's the only size image they can understand!\n",
        "\n",
        "> Note: It isn't *all* networks that need 224x224, just the ones we've looked at so far.\n",
        "\n",
        "**Update `IMAGE_SIZE` to reflect the size image our neural network will want.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H68s0yPZLQTC"
      },
      "source": [
        "# Magic numbers for success\n",
        "IMAGE_SIZE = (224, 224)\n",
        "IMAGE_SHAPE = IMAGE_SIZE + (3,)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae-JAAHX0FPK"
      },
      "source": [
        "## Loading our data\n",
        "\n",
        "When we did classification in class, we used `tf.keras.preprocessing.image_dataset_from_directory` to, well, load an image dataset from a directory! Since nothing can ever be simple, there are a hundred other ways to do it, too.\n",
        "\n",
        "This time we're going to use `flow_from_directory` instead. It works almost exactly the same, but it's more efficient if you need to do things like change `0-255` to `0-1` or perform image augmentations to get rotated/zoomed/flipped versions of your photos. Which I guess we do?\n",
        "\n",
        "**Change `data_dir` to point at to the folder that contains our images.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "ObPUr6VYLG_o",
        "outputId": "4c76b01d-5e32-4f98-f8da-37916a4ecc30"
      },
      "source": [
        "# Magic code for success\n",
        "data_dir = 'faces'\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.10)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, interpolation=\"bilinear\", class_mode='sparse')\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2, height_shift_range=0.2,\n",
        "    shear_range=0.2, zoom_range=0.2,\n",
        "    **datagen_kwargs)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b862ce9bc92e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     **datagen_kwargs)\n\u001b[1;32m      8\u001b[0m valid_generator = valid_datagen.flow_from_directory(\n\u001b[0;32m----> 9\u001b[0;31m     data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'faces'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md8wetUjGiDJ"
      },
      "source": [
        "The output should look like this:\n",
        "\n",
        "```\n",
        "Found 2777 images belonging to 536 classes.\n",
        "Found 27391 images belonging to 536 classes.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u27VwO4V1Zn1"
      },
      "source": [
        "## Building our model\n",
        "\n",
        "In class, we tried two approaches to building an image classifier:\n",
        "\n",
        "1. Use ImageNet's pre-trained 1,000 categories to figure out what was in images\n",
        "2. Use our own custom network and some custom images we downloaded to train a brand-new model\n",
        "\n",
        "It turns out there's also a third approach, where you **start with a model that knows about some things, but then you teach it to recognize new things.** This is called **transfer learning.**\n",
        "\n",
        "Transfer learning is useful because the model probably already knows about color and lines and circles and eyeballs and hair, which is how it knows a dog is different from an airplane. We just say hey, use what you know about color and lines and circles and eyeballs and hair to tell different people apart instead of dogs and planes!\n",
        "\n",
        "## Selecting a pre-trained model and architecture\n",
        "\n",
        "Below you have **three options** of models that you can start from.\n",
        "\n",
        "1. **MobileNet:** A network that is optimized for size, and so it's easier to transfer to mobile devices\n",
        "2. **ResNet 50:** A 50-layer residual network\n",
        "3. **ResNet 101:** A 101-layer residual network (like ResNet 50, just bigger)\n",
        "\n",
        "The difference is the \"magic insides\" that go between the inputs and the outputs - we don't understand what the insides are, but we still have to make a choice. They've all been trained on ImageNet, so they should in theory all know basically the same stuff.\n",
        "\n",
        "**Pick a pre-trained model by uncommenting one of the lines below, then running the cell.** If you want, you can read about them by visiting the URL in your browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMC8Ob9Z1NCC",
        "outputId": "ef4b9028-5d67-4afa-b41a-b1a6fe63494a"
      },
      "source": [
        "base_model_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "# base_model_url = \"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\"\n",
        "# base_model_url = \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/5\"\n",
        "\n",
        "# download the model from \n",
        "pretrained_model = hub.KerasLayer(base_model_url, trainable=False)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          activation='softmax')\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_1 (KerasLayer)   (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 536)               686616    \n",
            "=================================================================\n",
            "Total params: 2,944,600\n",
            "Trainable params: 686,616\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KnzOsrfLYj8"
      },
      "source": [
        "Remember: we're using a **softmax** layer at the end because we want probabilities! Softmax = probabilities!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LygMCTeS6EPa"
      },
      "source": [
        "## Settings for training our model\n",
        "\n",
        "Before we train, we need to `.compile` our model. Which I guess is just some sort of setup? It doesn't matter what it is, we just have to do it!!\n",
        "\n",
        "**Optimizer:** Our optimizer is `adam`, because that's... what people always use. Not *always* always, but since we don't even know what an optimizer is who cares.\n",
        "\n",
        "**Loss:** We're trying to predict categories, so our loss is either going to be `SparseCategoricalCrossentropy()` or `CategoricalCrossentropy()`. We aren't the first people to be confused about this, so maybe [read this question and answer](https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy) and try the one you think makes the most sense.\n",
        "\n",
        "**Metrics:** We want to make our classifier accurate, so our metric is... `accuracy`.\n",
        "\n",
        "**Set the appropriate loss function below.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KscuguMz1NJM"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o91EI9Q66WOu"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Here we go!!! Let's do it!!!\n",
        "\n",
        "**Pick the number of epochs you want to train for.** It's going to be a tradeoff between accuracy and how long it takes! Right now I have it set for a single epoch, which is definitely not enough.\n",
        "\n",
        "> If it's taking a really long time to train an epoch (more than 5-10 minutes), we want to make sure you're using the GPU! Click **Runtime** at the top of the screen, then **Change runtime type** and change **Hardware accelerator** to **GPU**. This will make everything faster.\n",
        "\n",
        "Even though Google Colab will let you run this for up to 12 hours, for this exercise I recommend not going any longer than an hour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I8A6Q2T6WYv",
        "outputId": "3bddf5ab-5a2f-47b9-fbf0-8f85d3ee045f"
      },
      "source": [
        "num_epochs = 7\n",
        "\n",
        "# This is a little more complicated than in class because we\n",
        "# are using that 'flow' loader instead of the 'images' loader\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "855/855 [==============================] - 330s 345ms/step - loss: 6.7740 - accuracy: 0.0126 - val_loss: 5.5103 - val_accuracy: 0.0596\n",
            "Epoch 2/7\n",
            "855/855 [==============================] - 299s 350ms/step - loss: 5.5784 - accuracy: 0.0627 - val_loss: 5.2809 - val_accuracy: 0.0916\n",
            "Epoch 3/7\n",
            "855/855 [==============================] - 296s 346ms/step - loss: 5.2040 - accuracy: 0.0942 - val_loss: 5.0264 - val_accuracy: 0.1141\n",
            "Epoch 4/7\n",
            "855/855 [==============================] - 293s 343ms/step - loss: 4.9330 - accuracy: 0.1245 - val_loss: 4.9651 - val_accuracy: 0.1366\n",
            "Epoch 5/7\n",
            "855/855 [==============================] - 295s 345ms/step - loss: 4.7886 - accuracy: 0.1397 - val_loss: 4.8141 - val_accuracy: 0.1639\n",
            "Epoch 6/7\n",
            "855/855 [==============================] - 294s 344ms/step - loss: 4.6277 - accuracy: 0.1556 - val_loss: 4.7572 - val_accuracy: 0.1682\n",
            "Epoch 7/7\n",
            "855/855 [==============================] - 294s 344ms/step - loss: 4.4947 - accuracy: 0.1723 - val_loss: 4.6991 - val_accuracy: 0.1781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b8e0a08d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCuEgr098Xo5"
      },
      "source": [
        "## Your results\n",
        "\n",
        "How did it do?\n",
        "\n",
        "`accuracy` is a measure of how good your model is at things it's already seen (e.g. the \"train\" part of train/test split) and `val_accuracy` is a measure of how good it is at things it *hasn't* seen (e.g. the \"test\" part of train/test split).\n",
        "\n",
        "**Paste the last couple line of output into the cell below.** It should look something like this:\n",
        "\n",
        "```python\n",
        "# Epoch 2/2\n",
        "# 855/855 [==============================] - 299s 349ms/step - loss: 5.5293 - accuracy: 0.0758 - val_loss: 5.1483 - val_accuracy: 0.1101\n",
        "```\n",
        "\n",
        "After pasting, comment them out so it doesn't try to run them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvpJ482o8saZ"
      },
      "source": [
        "#Epoch 9/10\n",
        "#855/855 [==============================] - 368s 430ms/step - loss: 4.3225 - accuracy: 0.1954 - val_loss: 4.6142 - val_accuracy: 0.1962\n",
        "#Epoch 10/10\n",
        "#855/855 [==============================] - 366s 428ms/step - loss: 4.2365 - accuracy: 0.2048 - val_loss: 4.6343 - val_accuracy: 0.1919"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJFN3SRKCLbY"
      },
      "source": [
        "## Save your model to Google Drive\n",
        "\n",
        "Instead of downloading our model, we'll just save it to our Google Drive. Since we don't have a GPU at home (right?? we're on a laptop??), it would probably run too slowly on our machine anyway."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "U5I0yyDCCLM9",
        "outputId": "6057503f-af95-4921-f03c-71aa92fc457f"
      },
      "source": [
        "# Make a new folder called \"models\" on our drive\n",
        "!mkdir -p /content/gdrive/MyDrive/models/face_recognition_v1\n",
        "\n",
        "# Save the model to that folder\n",
        "model.save('/content/gdrive/MyDrive/models/face_recognition_v1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive’: Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-c494020dde2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save the model to that folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/models/face_recognition_v1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2002\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m   def save_weights(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 157\u001b[0;31m                           signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;31m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;31m# the SavedModel proto itself.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m   \u001b[0mutils_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m   ckpt_options = checkpoint_options.CheckpointOptions(\n\u001b[1;32m   1040\u001b[0m       experimental_io_device=options.experimental_io_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/utils_impl.py\u001b[0m in \u001b[0;36mget_or_create_variables_dir\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    218\u001b[0m   \u001b[0mvariables_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvariables_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m   \"\"\"\n\u001b[0;32m--> 468\u001b[0;31m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m   \"\"\"\n\u001b[0;32m--> 483\u001b[0;31m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: /content/gdrive is not a directory"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcDlNie0Z1TE"
      },
      "source": [
        "We also need to save the names of everyone, because the model only knows numbers! Person 0, Person 1, Person 2, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRHuHgPMZ1cL",
        "outputId": "20e8085c-a881-4620-f9fd-d3d55f24dfe8"
      },
      "source": [
        "class_names = list(train_generator.class_indices.keys())\n",
        "class_names[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a._ferguson',\n",
              " 'a._mceachin',\n",
              " 'abigail_spanberger',\n",
              " 'adam_kinzinger',\n",
              " 'adam_schiff']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiCy_8ryZ8YM"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('/content/gdrive/MyDrive/models/congress_labels.json', 'w') as fp:\n",
        "  json.dump(class_names, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QM9G3IY8tE-"
      },
      "source": [
        "# Trying another model\n",
        "\n",
        "We're going to try another model instead of whatever you picked above. **And this time I'm telling you which one to use.** Our new model is built on ResNet50, but it can't tell a dog from an airplane!\n",
        "\n",
        "It turns out *there are other image classification datasets out there besides ImageNet!* Some of them are specific to things like cancerous cells or handwritten numbers, but we're going to make use of one that's all about **telling different faces apart.**\n",
        "\n",
        "There are a lot of options for \"standard datasets\" for training facial recognition systems. Some are based on random faces from the internet (FaceNet and VGGFace), while others are based on *just celebrities* (CelebNet, which seems kind of weird, honestly). There are probably other ones with mug shots and stuff, too.\n",
        "\n",
        "VGGFace2 is probably the most popular dataset these days, but I couldn't find a pre-trained VGGFace2 model that could easily work with Tensorflow 2! So instead we're going to use [a ResNet50 trained with FaceNet](https://github.com/nyoki-mtl/keras-facenet) by Hiroki Taniai, adapted for Tensorflow 2 by [Rajan Ghimire](https://github.com/R4j4n/Face-recognition-Using-Facenet-On-Tensorflow-2.X).\n",
        "\n",
        "In short: **we're using some random face-trained model from the internet instead of one trained on ImageNet.**\n",
        "\n",
        "## Defining the model\n",
        "\n",
        "Once upon a time we wrote our own model. It looked something like this:\n",
        "\n",
        "```python\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=IMAGE_SHAPE),\n",
        "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
        "])\n",
        "```\n",
        "\n",
        "That was a baby model for little babies. In order to use FaceNet, we need to grow up a little!\n",
        "\n",
        "Our new model is in the cell below. **Run it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEwHAHOErpxN"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Activation, Input, Add, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Concatenate, Lambda, add, GlobalAveragePooling2D, Convolution2D, LocallyConnected2D, ZeroPadding2D, concatenate, AveragePooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "def scaling(x, scale):\n",
        "\treturn x * scale\n",
        "\n",
        "def InceptionResNetV2():\n",
        "\tinputs = Input(shape=(160, 160, 3))\n",
        "\tx = Conv2D(32, 3, strides=2, padding='valid', use_bias=False, name= 'Conv2d_1a_3x3') (inputs)\n",
        "\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_1a_3x3_BatchNorm')(x)\n",
        "\tx = Activation('relu', name='Conv2d_1a_3x3_Activation')(x)\n",
        "\tx = Conv2D(32, 3, strides=1, padding='valid', use_bias=False, name= 'Conv2d_2a_3x3') (x)\n",
        "\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_2a_3x3_BatchNorm')(x)\n",
        "\tx = Activation('relu', name='Conv2d_2a_3x3_Activation')(x)\n",
        "\tx = Conv2D(64, 3, strides=1, padding='same', use_bias=False, name= 'Conv2d_2b_3x3') (x)\n",
        "\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_2b_3x3_BatchNorm')(x)\n",
        "\tx = Activation('relu', name='Conv2d_2b_3x3_Activation')(x)\n",
        "\tx = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n",
        "\tx = Conv2D(80, 1, strides=1, padding='valid', use_bias=False, name= 'Conv2d_3b_1x1') (x)\n",
        "\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_3b_1x1_BatchNorm')(x)\n",
        "\tx = Activation('relu', name='Conv2d_3b_1x1_Activation')(x)\n",
        "\tx = Conv2D(192, 3, strides=1, padding='valid', use_bias=False, name= 'Conv2d_4a_3x3') (x)\n",
        "\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_4a_3x3_BatchNorm')(x)\n",
        "\tx = Activation('relu', name='Conv2d_4a_3x3_Activation')(x)\n",
        "\tx = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Conv2d_4b_3x3') (x)\n",
        "\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_4b_3x3_BatchNorm')(x)\n",
        "\tx = Activation('relu', name='Conv2d_4b_3x3_Activation')(x)\n",
        "\t\n",
        "\t# 5x Block35 (Inception-ResNet-A block):\n",
        "\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block35_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_1_Conv2d_0b_3x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_1_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n",
        "\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0a_1x1') (x)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0b_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0c_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n",
        "\tbranches = [branch_0, branch_1, branch_2]\n",
        "\tmixed = Concatenate(axis=3, name='Block35_1_Concatenate')(branches)\n",
        "\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_1_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block35_1_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block35_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_2_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_1_Conv2d_0b_3x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_2_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n",
        "\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0a_1x1') (x)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0b_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0c_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n",
        "\tbranches = [branch_0, branch_1, branch_2]\n",
        "\tmixed = Concatenate(axis=3, name='Block35_2_Concatenate')(branches)\n",
        "\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_2_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block35_2_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block35_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_3_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_1_Conv2d_0b_3x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_3_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n",
        "\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0a_1x1') (x)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0b_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0c_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n",
        "\tbranches = [branch_0, branch_1, branch_2]\n",
        "\tmixed = Concatenate(axis=3, name='Block35_3_Concatenate')(branches)\n",
        "\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_3_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block35_3_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block35_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_4_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_1_Conv2d_0b_3x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_4_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n",
        "\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0a_1x1') (x)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0b_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0c_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n",
        "\tbranches = [branch_0, branch_1, branch_2]\n",
        "\tmixed = Concatenate(axis=3, name='Block35_4_Concatenate')(branches)\n",
        "\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_4_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block35_4_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block35_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_5_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_1_Conv2d_0b_3x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block35_5_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n",
        "\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0a_1x1') (x)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0b_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0c_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n",
        "\tbranches = [branch_0, branch_1, branch_2]\n",
        "\tmixed = Concatenate(axis=3, name='Block35_5_Concatenate')(branches)\n",
        "\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_5_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block35_5_Activation')(x)\n",
        "\n",
        "\t# Mixed 6a (Reduction-A block):\n",
        "\tbranch_0 = Conv2D(384, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_6a_Branch_0_Conv2d_1a_3x3') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_0_Conv2d_1a_3x3_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Mixed_6a_Branch_0_Conv2d_1a_3x3_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, 3, strides=1, padding='same', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_0b_3x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_1a_3x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_1a_3x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_1a_3x3_Activation')(branch_1)\n",
        "\tbranch_pool = MaxPooling2D(3, strides=2, padding='valid', name='Mixed_6a_Branch_2_MaxPool_1a_3x3')(x)\n",
        "\tbranches = [branch_0, branch_1, branch_pool]\n",
        "\tx = Concatenate(axis=3, name='Mixed_6a')(branches)\n",
        "\n",
        "\t# 10x Block17 (Inception-ResNet-B block):\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_1_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_1_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_1_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_2_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_2_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_2_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_3_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_3_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_3_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_4_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_4_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_4_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_5_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_5_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_5_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_6_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_6_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_6_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_6_Activation')(x)\t\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_7_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_7_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_7_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_7_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_8_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_8_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_8_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_8_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_9_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_9_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_9_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_9_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block17_10_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0b_1x7') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0b_1x7_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0b_1x7_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0c_7x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0c_7x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0c_7x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block17_10_Concatenate')(branches)\n",
        "\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_10_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block17_10_Activation')(x)\n",
        "\n",
        "\t# Mixed 7a (Reduction-B block): 8 x 8 x 2080\t\n",
        "\tbranch_0 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_0_Conv2d_0a_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_0_Conv2d_0a_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Mixed_7a_Branch_0_Conv2d_0a_1x1_Activation')(branch_0)\n",
        "\tbranch_0 = Conv2D(384, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_0_Conv2d_1a_3x3') (branch_0)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_0_Conv2d_1a_3x3_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Mixed_7a_Branch_0_Conv2d_1a_3x3_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Mixed_7a_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_1_Conv2d_1a_3x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_1_Conv2d_1a_3x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Mixed_7a_Branch_1_Conv2d_1a_3x3_Activation')(branch_1)\n",
        "\tbranch_2 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_0a_1x1') (x)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(256, 3, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_0b_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n",
        "\tbranch_2 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_1a_3x3') (branch_2)\n",
        "\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_1a_3x3_BatchNorm')(branch_2)\n",
        "\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_1a_3x3_Activation')(branch_2)\n",
        "\tbranch_pool = MaxPooling2D(3, strides=2, padding='valid', name='Mixed_7a_Branch_3_MaxPool_1a_3x3')(x)\n",
        "\tbranches = [branch_0, branch_1, branch_2, branch_pool]\n",
        "\tx = Concatenate(axis=3, name='Mixed_7a')(branches)\n",
        "\n",
        "\t# 5x Block8 (Inception-ResNet-C block):\n",
        "\t\n",
        "\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block8_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0b_1x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0b_1x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0b_1x3_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0c_3x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0c_3x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0c_3x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block8_1_Concatenate')(branches)\n",
        "\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_1_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block8_1_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block8_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0b_1x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0b_1x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0b_1x3_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0c_3x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0c_3x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0c_3x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block8_2_Concatenate')(branches)\n",
        "\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_2_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block8_2_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block8_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0b_1x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0b_1x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0b_1x3_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0c_3x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0c_3x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0c_3x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block8_3_Concatenate')(branches)\n",
        "\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_3_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block8_3_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block8_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0b_1x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0b_1x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0b_1x3_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0c_3x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0c_3x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0c_3x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block8_4_Concatenate')(branches)\n",
        "\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_4_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block8_4_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block8_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0b_1x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0b_1x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0b_1x3_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0c_3x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0c_3x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0c_3x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block8_5_Concatenate')(branches)\n",
        "\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_5_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n",
        "\tx = add([x, up])\n",
        "\tx = Activation('relu', name='Block8_5_Activation')(x)\n",
        "\t\n",
        "\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_0_Conv2d_1x1') (x)\n",
        "\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n",
        "\tbranch_0 = Activation('relu', name='Block8_6_Branch_0_Conv2d_1x1_Activation')(branch_0)\n",
        "\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0a_1x1') (x)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0b_1x3') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0b_1x3_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0b_1x3_Activation')(branch_1)\n",
        "\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0c_3x1') (branch_1)\n",
        "\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0c_3x1_BatchNorm')(branch_1)\n",
        "\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0c_3x1_Activation')(branch_1)\n",
        "\tbranches = [branch_0, branch_1]\n",
        "\tmixed = Concatenate(axis=3, name='Block8_6_Concatenate')(branches)\n",
        "\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_6_Conv2d_1x1') (mixed)\n",
        "\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 1})(up)\n",
        "\tx = add([x, up])\n",
        "\t\n",
        "\t# Classification block\n",
        "\tx = GlobalAveragePooling2D(name='AvgPool')(x)\n",
        "\tx = Dropout(1.0 - 0.8, name='Dropout')(x)\n",
        "\t# Bottleneck\n",
        "\tx = Dense(128, use_bias=False, name='Bottleneck')(x)\n",
        "\tx = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False, name='Bottleneck_BatchNorm')(x)\n",
        "\n",
        "\t# Create model\n",
        "\tmodel = Model(inputs, x, name='inception_resnet_v1')\n",
        "\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elYxsLTE_eOc"
      },
      "source": [
        "Fun, right?\n",
        "\n",
        "To use a pre-trained model, we need two things:\n",
        "\n",
        "1. The **model architecture:** what the \"magic inside\" layers look like, and \n",
        "2. The **model weights:** what the \"magic inside\" layers learned from training, e.g. \n",
        "\n",
        "Previously we just pointed Tensorflow at some URL to download all of that info, but now we need to do it manually.\n",
        "\n",
        "The giant cell above defined the **model architecture** (in this case, ResNet50). Now we need to **give it the pre-trained weights!**\n",
        "\n",
        "Download `facenet_keras_weights.h5` from CourseWorks or [my Google Drive](https://drive.google.com/file/d/1DCU55aVf93bz7kAYmWrFc1G91-cyf6Js/view?usp=sharing) and upload it to Colab. You should be able to just drag-and-drop into the area to the left of here. You can also upload to Google Drive and use the copy command from up above like we did with `faces.zip` in the very beginning.\n",
        "\n",
        "After it's done uploading – which might take a while, watch the little circle on the bottom left of the screen – **run the cell below to import the pre-trained weights.**\n",
        "\n",
        "> If we were very wealthy, had a lot of time, and didn't care about the enviroment, another option would be to download the FaceNet dataset and train our model from scratch. But instead: *we're lazy.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRmNzvfB_b8T"
      },
      "source": [
        "# Create the FaceNet model\n",
        "pretrained_face_model = InceptionResNetV2()\n",
        "\n",
        "# # Load the weights of the model\n",
        "pretrained_face_model.load_weights(\"facenet_keras_weights.h5\")\n",
        "pretrained_face_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htrMiyYwAzYs"
      },
      "source": [
        "## Set up our new model\n",
        "\n",
        "Now we have our nice new `pretrained_face_encoder`, ready to go!\n",
        "\n",
        "Last time we built our model, it looked like this:\n",
        "\n",
        "```python\n",
        "# base_model_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "# base_model_url = \"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\"\n",
        "# base_model_url = \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/5\"\n",
        "\n",
        "# download the model from \n",
        "pretrained_model = hub.KerasLayer(base_model_url, trainable=False)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          activation='softmax')\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "**Copy and paste this code into the cell below.**\n",
        "\n",
        "We'll then need to make **two changes** to use our new model:\n",
        "\n",
        "1. Change this code to use the `pretrained_face_model` instead of the model downloaded from tfhub.\n",
        "2. FaceNet didn't use 224x224 images, so we'll need to change `IMAGE_SIZE`. Can you look at the awful, long cell where we defined the architecture to see what the new image size needs to be? *Hint: it's pretty close to the top!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA2aCf8pc7yH"
      },
      "source": [
        "IMAGE_SIZE = (160, 160)\n",
        "IMAGE_SHAPE = IMAGE_SIZE + (3,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIh7FkZkMe9H",
        "outputId": "d42d3bbc-be81-4866-aa5f-3884929c12c2"
      },
      "source": [
        "base_model_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "# base_model_url = \"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\"\n",
        "# base_model_url = \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/5\"\n",
        " \n",
        "# download the model from \n",
        "pretrained_model = hub.KerasLayer(pretrained_face_model, trainable=False)\n",
        " \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3, )),\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          activation='softmax')\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3, ))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_3 (KerasLayer)   (None, 128)               22808144  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 536)               69144     \n",
            "=================================================================\n",
            "Total params: 22,877,288\n",
            "Trainable params: 69,144\n",
            "Non-trainable params: 22,808,144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQHw2MD6c6TI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUJSRDePB7KF"
      },
      "source": [
        "## Compile and train the model\n",
        "\n",
        "You can copy and paste the same code from the `model.compile` and `model.fit` cells we used before to train this model.\n",
        "\n",
        "**How many epochs should you use this time?** Feel free to experiment with different numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUs0GYAG9XLB",
        "outputId": "a4b8e80e-5d33-4f27-cb79-fc52d72bafad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdIlYcKtNf_I"
      },
      "source": [
        "# model.compile code goes here\n",
        "model.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT_LI_y5MhWg",
        "outputId": "bf15a3c1-a406-4759-c4a5-877e85922463"
      },
      "source": [
        "# num_epochs/fit/etc code goes here\n",
        "num_epochs = 7\n",
        "\n",
        "# This is a little more complicated than in class because we\n",
        "# are using that 'flow' loader instead of the 'images' loader\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "855/855 [==============================] - 437s 469ms/step - loss: 6.1852 - accuracy: 0.0165 - val_loss: 4.9729 - val_accuracy: 0.2762\n",
            "Epoch 2/7\n",
            "855/855 [==============================] - 393s 460ms/step - loss: 5.5864 - accuracy: 0.1051 - val_loss: 4.1703 - val_accuracy: 0.4066\n",
            "Epoch 3/7\n",
            "855/855 [==============================] - 391s 458ms/step - loss: 5.2675 - accuracy: 0.1611 - val_loss: 3.6555 - val_accuracy: 0.4731\n",
            "Epoch 4/7\n",
            "855/855 [==============================] - 388s 454ms/step - loss: 5.0773 - accuracy: 0.1889 - val_loss: 3.3209 - val_accuracy: 0.5145\n",
            "Epoch 5/7\n",
            "855/855 [==============================] - 384s 448ms/step - loss: 4.9390 - accuracy: 0.2084 - val_loss: 3.0982 - val_accuracy: 0.5400\n",
            "Epoch 6/7\n",
            "855/855 [==============================] - 382s 447ms/step - loss: 4.8797 - accuracy: 0.2160 - val_loss: 2.9413 - val_accuracy: 0.5596\n",
            "Epoch 7/7\n",
            "855/855 [==============================] - 382s 446ms/step - loss: 4.8052 - accuracy: 0.2262 - val_loss: 2.8298 - val_accuracy: 0.5752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8488dc5510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F04FAEiBWf3p"
      },
      "source": [
        "## How did it do?\n",
        "\n",
        "Just like we did before, paste the last epoch result below. Be sure to comment it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5heQqil5WgE_"
      },
      "source": [
        "#Epoch 7/7\n",
        "#855/855 [==============================] - 382s 446ms/step - loss: 4.8052 - accuracy: 0.2262 - val_loss: 2.8298 - val_accuracy: 0.5752\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmrwLGmWDrnI"
      },
      "source": [
        "## Save your model\n",
        "\n",
        "We'll save this model, too! Our last one was `face_recognition_v1`, so this one can be `face_recognition_v2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_mSK44kDpK6"
      },
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/models/face_recognition_v2\n",
        "model.save('/content/gdrive/MyDrive/models/face_recognition_v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVY1gxs5LtbO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEl6nXZ2ZSZm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epZzTJe0ZsAo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}